{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Cercare-Medical ML Project","text":"Machine Learning Based Advanced MR and CT Series Type Detection Jeongsoo Pang     Cercare-Medical R&amp;D     ML-Specialist     2024.06.01 - 2024.12.01"},{"location":"#abstract","title":"Abstract","text":"<p>Radiology workflows depend on correctly identifying series types (e.g., MR: DWI, SWI, T1, T2 FLAIR; CT: Angio/Perfusion/Noncontrast) before reconstruction, analysis, or visualization. Vendor-specific DICOM conventions, private tags, nested data, multilingual fields, and missing metadata make rule-based detectors unreliable. This project delivers a production-ready ML pipeline that automatically classifies 8 MR and 3 CT series using only DICOM header metadata. </p> <p>It features: 1. A robust feature-extraction module handling private/nested tags and multilingual headers. 2. Two HistGradientBoosting (HGBC) models\u2014trained with and without <code>SeriesDescription</code>\u2014to remain robust when textual labels are missing or inconsistent. 3. A self-inspection mechanism that flags low-confidence predictions to radiologists for review.</p> <p>Externally validated on partner-hospital datasets, the model achieved 96.69% MR and 99.25% CT accuracy, replacing the legacy C++ detector in production. The design emphasizes maintainability, future retraining, and clinical safety.</p>"},{"location":"#project-goal","title":"Project Goal","text":"<ul> <li>Build an ML model to classify 8 MR and 3 CT series, replacing the company\u2019s rule-based detector.  </li> <li>Ensure the model is easy to retrain for new series and safe to deploy through confidence-based self-inspection.  </li> </ul>"},{"location":"#my-contributions","title":"My Contributions","text":"<ul> <li>Engineered DICOM Header Extractor</li> <li>Data De-biasing: one representative DICOM per 3D study.  </li> <li>Feature Preprocessing for numeric + categorical + missing/string values.  </li> <li>Dual-Model Training: HGBC with/without <code>SeriesDescription</code>.  </li> <li>Self-Inspection Gate with confidence thresholds and top-2 margin.  </li> <li>External Validation &amp; Deployment with hospitals; production replacement.  </li> <li>Explainability with SHAP; reproducible JSON/serialized pipelines.</li> </ul>"},{"location":"#dataset-summary","title":"Dataset Summary","text":"Modality Train Test MR 171 185 CT 271 407 <p>MR (8): <code>pwi_dsc</code>, <code>pwi_dce</code>, <code>swi</code>, <code>dwi</code>, <code>t2</code>, <code>t2_flair</code>, <code>t1</code>, <code>t1_contrast</code> CT (3): <code>ct_angiography</code>, <code>ct_perfusion</code>, <code>ct_noncontrast</code></p>"},{"location":"#feature-overview","title":"Feature Overview","text":"<p>MR: <code>NumberTemporalPositions</code>, <code>PhaseEncodingDirection</code>, <code>RepetitionTime</code>, <code>FlipAngle</code>, <code>InversionTime</code>, <code>EchoTrainLength</code>, <code>MagneticFieldStrength</code>, <code>EchoSpacing</code>, <code>PulseSequenceName</code>, <code>SequenceVariant</code>, <code>Bvalue</code>, <code>ScanOptions</code> </p> <p>CT: <code>ContrastBolusAgent</code>, <code>ExposureTime</code>, <code>KVP</code>, <code>ScanOptions</code>, <code>ReconstructionDiameter</code>, <code>ConvolutionKernel</code>, <code>TableSpeed</code>, <code>SeriesTime</code>, <code>Modality</code></p>"},{"location":"#pipeline-overview","title":"Pipeline Overview","text":"<ol> <li>Ingestion: select one DICOM per 3D series from Blackbox server.  </li> <li>Feature Extraction \u2192 normalized, grouped JSON.  </li> <li>Preprocessing: imputation + one-hot (unknown-safe).  </li> <li>Training (HGBC): tuned <code>max_iter=100</code>, <code>lr=0.1</code>, <code>max_leaf_nodes=31</code>, <code>early_stopping='auto'</code>, <code>validation_fraction=0.1</code>.  </li> <li>Selective Prediction: abstain on low confidence or tight top-2.  </li> <li>Validation/Deployment: external datasets; production replacement.</li> </ol>"},{"location":"#training-hyperparameter-tuning","title":"Training &amp; Hyperparameter Tuning","text":"<p>I treated tuning as an engineering task, not guesswork.</p> <p>Search space (HGBC): - <code>learning_rate \u2208 {0.03, 0.05, 0.07, 0.1}</code> - <code>max_iter \u2208 {200, 400, 800}</code> (with early stopping) - <code>max_leaf_nodes \u2208 {15, 31, 63}</code> - <code>min_samples_leaf \u2208 {10, 20, 40}</code> - <code>l2_regularization \u2208 {0.0, 0.01, 0.05, 0.1}</code> - <code>early_stopping='auto'</code>, <code>validation_fraction=0.1</code>, <code>n_iter_no_change=20</code></p> <p>Protocol: 1. Stratified 5-fold CV on training (patient-level split) to avoid leakage. 2. Random search (200 trials) \u2192 Bayesian refinement (20 trials) on top 10% configs. 3. Class-imbalance control: per-class weighting from inverse frequency; verified no single class dominated loss. 4. Feature pipelines locked (scalers/encoders fit only on train folds) to guarantee reproducibility. 5. Model selection objective: macro-F1 with a tie-breaker on AUROC and coverage at the selective-prediction threshold.</p> <p>Best config (typical): HGBC( learning_rate=0.07, max_iter=400, max_leaf_nodes=31, min_samples_leaf=20, l2_regularization=0.05, early_stopping='auto', validation_fraction=0.1 )</p> <p>Why not plain GBC? On the same folds, plain GBC matched accuracy only when much deeper trees were allowed\u2014training was 3-6\u00d7 slower and variance across folds was higher. With HGBC, histogram binning plus <code>min_samples_leaf</code> gave smoother loss curves and earlier stopping without sacrificing recall on minority classes.</p>"},{"location":"#model-choice-rationale-histgradientboosting-hgbc","title":"Model Choice &amp; Rationale \u2014 HistGradientBoosting (HGBC)","text":"<p>I compared tree-based learners (RandomForest, GradientBoostingClassifier), linear baselines, and HGBC. HGBC won for this use-case:</p> Criterion HGBC (Chosen) Plain GBC Why it matters for DICOM-header metadata Training speed on medium/large tabular data Histogram binning (fast) Exact splits (slow) Faster iteration for tuning/validation on hospital-scale datasets Native handling of missing values Yes Partial/No Robust to sparsity and vendor-specific header gaps Early stopping &amp; validation split Built-in Manual Safe convergence + automatic regularization Regularization knobs <code>l2_regularization</code>, <code>min_samples_leaf</code>, <code>max_leaf_nodes</code> Fewer stable knobs Tighter control \u2192 less overfit on small classes Interpretability Tree-based; SHAP works well Same Feature attributions for clinical QA"},{"location":"#explainability-robustness-model-safety","title":"Explainability, Robustness &amp; Model Safety","text":"<ul> <li>SHAP-based attributions shipped with predictions for audit-readiness; top contributors were TR/TE/FA and sequence-family tags, matching domain intuition.</li> <li>Counterfactual probes: perturbed non-causal strings in textual headers to ensure predictions stayed stable; drift alarms if contribution of text fields spikes.</li> <li>Selective-prediction policy: abstain when (1) max prob &lt; \u03c4\u2081 or (2) top-2 prob gap &lt; \u03c4\u2082; thresholds chosen on validation for F1@coverage.</li> <li>Calibration: isotonic mapping per fold; stored along with the model for consistent probability semantics.</li> <li>Data privacy &amp; governance: PHI removed upstream; experiments run on anonymized headers only; reproducible artifact hashes tracked.</li> </ul>"},{"location":"#deployment-reproducibility","title":"Deployment &amp; Reproducibility","text":"<ul> <li>Single Sklearn Pipeline: <code>preprocess \u2192 model \u2192 calibration \u2192 selective gate</code>; versioned with semantic tags.</li> <li>Determinism: fixed RNG seeds, pinned package versions, and input schema checks (pydantic) at load time.</li> <li>Experiment tracking: run metadata (params, metrics, SHAP summaries, data snapshot hash) logged for every training job.</li> <li>CI checks: unit tests for feature extractors; regression tests to ensure no drift in per-class recall.</li> <li>Monitoring: in production, log coverage/abstention rate and top-k feature drifts; alerts when coverage &lt; 95% or class recall falls &gt; 3pp.</li> </ul>"},{"location":"#evaluation-protocol-metrics","title":"Evaluation Protocol &amp; Metrics","text":"<ul> <li>Splits: patient-level train/val/test; external partner hospitals held-out for final reporting.</li> <li>Primary metrics: macro-F1 (class balance), per-class recall (clinical safety), and overall accuracy.</li> <li>Selective prediction: tuned a probability-margin gate to maximize F1 @ \u226595% coverage; abstentions trigger radiologist review.</li> <li>Calibration: verified reliability via isotonic calibration on validation folds; ECE &lt; 3% on test.</li> <li>Ablations: </li> <li>Text present vs missing <code>SeriesDescription</code> (two-model strategy)  </li> <li>Remove top-k features (stability check)  </li> <li>Swap HGBC\u2192GBC/RandomForest (model choice justification)</li> </ul>"},{"location":"#results-summary","title":"Results Summary","text":"<p>External partner-hospital validation: MR 96.69%, CT 99.25%. Deployed to production; supports safe retraining and human-in-the-loop.</p>"},{"location":"#limitations-next-steps","title":"Limitations &amp; Next Steps","text":"<ul> <li>Cross-vendor generalization: performance is strong but varies on rare protocol variants; plan targeted augmentation and vendor-specific priors.</li> <li>Long-tail classes: continue collecting underrepresented sequences; consider focal loss proxy via class weights and threshold per class.</li> <li>Lightweight text normalization: subword normalization for multilingual <code>SeriesDescription</code> without relying on full NLP stacks.</li> <li>Automated drift triggers: schedule retrain when coverage dips, calibration ECE rises, or SHAP distributions drift beyond control limits.</li> </ul>"},{"location":"#acknowledgment","title":"Acknowledgment","text":"<p>This project was conducted under Cercare-Medical, Denmark (2024) with direct collaboration with the Lead AI Developer, Senior Software Developers, and Operation Team, resulting in a successful production deployment and recommendation Letter from the CTO.</p> <p> </p>"},{"location":"anti_drone/","title":"Anti-Drone Project","text":"Anti-Drone Project \u2014 FMCW Radar &amp; Electro-Optical Fusion Jeongsoo Pang     AI Capacity Competition by Korean National Defense     FMCW Radar Signal &amp; Image Intelligence     2023.11"},{"location":"anti_drone/#abstract","title":"Abstract","text":"<p>The Anti-Drone Project focused on developing a reliable, low-latency machine learning pipeline to detect and classify UAVs using FMCW radar spectrograms and RCS imagery. The system integrates classical machine learning (SVM, Random Forest, Gradient Boosting) and deep convolutional architectures (AlexNet, ResNet, GoogLeNet, NasNet, SqueezeNet) to achieve optimal trade-offs between accuracy, robustness, and real-time inference on edge devices.</p>"},{"location":"anti_drone/#project-objective","title":"Project Objective","text":"<ul> <li>Build an end-to-end ML framework for drone detection and classification from Doppler and RCS data.</li> <li>Benchmark traditional classifiers versus deep CNN backbones for FMCW spectrograms.</li> <li>Evaluate robustness under noise, latency, and hardware constraints for embedded radar platforms.</li> <li>Provide a research-grade reproducible implementation with clear documentation and modularity.</li> </ul>"},{"location":"anti_drone/#dataset-preprocessing","title":"Dataset &amp; Preprocessing","text":"Dataset Description Modality Goorm-AI-04 Drone Doppler FMCW radar Doppler spectrograms labeled by drone type FMCW Spectrogram Goorm-AI-04 RCS Image Radar cross-section images of drone surfaces RCS Imagery Real Doppler RAD-DAR (Kaggle) Real Doppler datasets recorded by the RAD-DAR radar system, a widely used platform internationally FMCW Doppler Drone Remote Controller RF Signal (IEEE Dataport) RF baseband captures from drone remote controllers for auxiliary signal analysis RF / I/Q <ul> <li>Flattening &amp; Normalization: Converted radar tensors to 224 \u00d7 224 gray-scale arrays, normalized with ImageNet statistics for transfer learning compatibility.  </li> <li>Noise Augmentation: Simulated Gaussian noise at \u03c3\u00b2 \u2208 {1e-4 \u2026 1e-2} to evaluate noise tolerance of SVC, HGBC, and RF models.  </li> <li>Stratified Splits: Ensured balanced representation across drone types with 10% validation sets.  </li> <li>Dynamic Range Calibration: Capped and floor-normalized pixel intensities to mitigate power spikes and saturation artifacts.</li> </ul>"},{"location":"anti_drone/#model-architectures","title":"Model Architectures","text":""},{"location":"anti_drone/#classical-ml-models","title":"Classical ML Models","text":"Model Core Idea Strength LinearSVC / SVC Multi-class margin-maximization on flattened radar frames Fast, interpretable Random Forest Classifier Ensemble of decision trees with bagging Noise-robust HistGradientBoosting Classifier Histogram-based boosting with native categorical support High accuracy / structured data SGDClassifier Online linear optimization baseline Lightweight reference"},{"location":"anti_drone/#deep-cnn-backbones","title":"Deep CNN Backbones","text":"Model Parameter (M) Notes AlexNet 61.0 Classic CNN baseline for radar texture learning GoogLeNet 6.8 Inception-based multi-scale spatial features ResNet-34 / ResNet-101 21.3 / 44.5 Residual skip-connections for stable training SqueezeNet 1.2 Lightweight model ideal for embedded inference NasNet 5.3 Neural architecture search optimized backbone MobileNetV2 3.5 Depthwise separable convs; strong accuracy/FLOPs ratio <p>All deep networks were fine-tuned from PyTorch ImageNet weights, with a custom three-class output layer corresponding to drone categories (quadrotor, fixed-wing, multi-rotor).</p>"},{"location":"anti_drone/#training-strategy","title":"Training Strategy","text":"<ul> <li>Framework: PyTorch + (optional) Hugging Face + W&amp;B logging.  </li> <li>Batch Size: 128 (train) / 20 (eval).  </li> <li>Epochs: 8\u201312 with early stopping and cosine LR scheduler.  </li> <li>Optimizer: AdamW (lr \u2208 {1e-4, 5e-4, 1e-3, 1e-2}, weight decay = 1e-3).  </li> <li>Mixed Precision (FP16): Enabled where supported for throughput.  </li> <li>Metric Callback: Custom <code>compute_metrics()</code> tracking accuracy, F1, precision, recall, and AUC.  </li> <li>Hyperparameter Search: Grid over learning rates and batch sizes + W&amp;B sweeps for convergence profiling.</li> </ul>"},{"location":"anti_drone/#evaluation-methodology","title":"Evaluation Methodology","text":"<ul> <li>Cross-Validation: 10% validation per seed \u2208 {21, 42, 77}.  </li> <li>Noise Perturbation Tests: Measured model accuracy across \u03c3\u00b2 \u2208 {1e-4 \u2026 1e-2} noise levels.  </li> <li>Inference Profiling: Averaged 100 runs to estimate per-image latency (<code>perf_counter()</code> loop).  </li> <li>Metrics: Micro-averaged F1, precision/recall, and timing std (\u03bc \u00b1 \u03c3).</li> </ul>"},{"location":"anti_drone/#results-summary","title":"Results Summary","text":"Model Accuracy (%) F1 Avg Inference (s) Params (M) Linear SVC 92.4 0.92 0.004 \u2013 Hist GB Classifier 95.1 0.95 0.007 \u2013 Random Forest 94.8 0.94 0.009 \u2013 SqueezeNet 97.3 0.97 0.012 1.2 ResNet-34 96.5 0.96 0.017 21.3 GoogLeNet 96.9 0.96 0.015 6.8 <p>SqueezeNet achieved the best accuracy-efficiency balance, making it the production-ready model for real-time radar deployment.</p>"},{"location":"anti_drone/#additional-experiment-noise-on-image-datasets","title":"Additional Experiment \u2014 Noise on Image Datasets","text":"<p>To stress-test robustness, we performed accuracy experiments on noise-added image datasets (Gaussian noise with \u03c3\u00b2 \u2208 {1e-4 \u2026 1e-2}). We evaluated both CNNs and classical models:</p> <ul> <li>CNNs: ResNet-101, GoogLeNet, MobileNetV2 </li> <li>Classical: SVC, Linear SVC, Gradient Boosted Decision Trees (HistGBDT), Random Forest</li> </ul> <p>The plot below summarizes accuracy by model across noise levels:</p> <p></p> <p>Key takeaways: - MobileNetV2 and GoogLeNet maintained high accuracy up to moderate noise due to depthwise separable/inception multi-scale features. - ResNet-101 remained the most stable at higher noise regimes, likely due to deeper residual capacity and batch-norm smoothing. - Among classical models, HistGBDT outperformed RF and SVC under heavier noise, aligning with its histogram-binning robustness.</p>"},{"location":"anti_drone/#technical-highlights","title":"Technical Highlights","text":"<ul> <li>Hybrid Experimentation Framework: Unified classical + deep models within a single harness for direct benchmarking.  </li> <li>Custom Collate Fn: Converted raw radar tensors into 3-channel images via NumPy + PIL augmentation before Torch batching.  </li> <li>W&amp;B Integration: Auto-logged metrics, confusion matrices, parameter sweeps, and artifacts with reproducible seeds.  </li> <li>Cross-Domain Validation: Consistent &gt;96% accuracy on unseen test and noise-augmented datasets.  </li> <li>Explainability: Interpreted radar spectrogram activations using Grad-CAM to validate model attention on micro-Doppler regions.</li> </ul>"},{"location":"anti_drone/#deployment-considerations","title":"Deployment Considerations","text":"<ul> <li>Edge Inference Optimization: Quantized SqueezeNet to FP16, achieving &gt;80 FPS on Jetson Nano.  </li> <li>Model Serialization: Exported via TorchScript for embedded radar pipeline.  </li> <li>Noise-Aware Retraining: Integrated Gaussian perturbation generator for continual retraining in field conditions.</li> </ul>"},{"location":"anti_drone/#future-work","title":"Future Work","text":"<ul> <li>Real-time fusion with EO/IR imagery via feature-level concatenation.  </li> <li>Temporal smoothing (LSTM / Transformer) for tracking moving drones.  </li> <li>Radar signature augmentation using simulated micro-Doppler patterns.</li> </ul>"},{"location":"anti_drone/#repository-structure","title":"Repository Structure","text":"<p>Link to Repository: https://github.com/jpangece/Anti_Drone_System</p> File Description <code>AlexNet.py</code>, <code>GoogLeNet.py</code>, <code>ResNet34.py</code>, <code>ResNet101.py</code>, <code>SqueezeNet.py</code>, <code>NasNet.py</code> Deep CNN backbones (TorchVision compatible) <code>RandomForest.py</code>, <code>SVM_SB_RFC.py</code> Classical ML baselines (SVM, RF, HistGBDT) <code>README.md</code> Documentation and experimental setup <code>wandb/</code> Training logs, sweeps, and performance dashboards"},{"location":"anti_drone/#acknowledgment","title":"Acknowledgment","text":"<p>This work was part of a collaborative defense-AI initiative, integrating FMCW radar and EO sensor data for UAV detection. All experiments were executed using PyTorch 2.0 and W&amp;B, with full experiment reproducibility ensured via deterministic seeds and dataset versioning.</p>"},{"location":"remote_chair/","title":"Remote Feeling Mimicking Chair","text":"Remote Feeling Mimicking Chair \u2014 Low-Latency Dual-Chair Haptic Teleoperation Jeongsoo Pang     UM\u2013SJTU Joint Institute &amp; BuilderX (sponsor)     2025 Design Expo    Abstract <p> This project presents a dual-chair haptic teleoperation system that reproduces both the tilt (pitch/roll) and vibration of a remote operator\u2019s seat in real time. Using a three-actuator Stewart-inspired platform driven by 24 V DC linear actuators, the system achieves a \u00b115\u00b0 motion range and an actuation speed of approximately 84 mm/s. A 6-axis ICM-45686 IMU mounted on the remote chair streams motion data over Bluetooth Low Energy (BLE) with sub-10 ms latency to an ESP32 controller that performs real-time inverse-kinematics control through BTS7960 PWM drivers. A multi-threaded firmware running on FreeRTOS ensures parallel handling of IMU sampling, BLE communication, and actuator feedback, producing smooth motion transitions with negligible delay. Experimental validation at the 2025 SJTU Design Expo confirmed stable operation. </p>"},{"location":"remote_chair/#system-overview","title":"System Overview","text":"<p>The Remote Feeling Mimicking Chair (RFMC) consists of two physically separate yet electronically synchronized platforms:</p> <ul> <li>Chair 1 (Source): Mounted on a moving machine or vehicle; captures inertial data via IMU.  </li> <li>Chair 2 (Replica): Receives data, reconstructs tilt and vibration in real time.</li> </ul> <p>Each chair integrates mechanical, electrical, and firmware subsystems optimized for modular assembly, low cost, and human safety. BLE is used for its ultra-low latency and native multithreading support on ESP32, allowing command rates up to 300 Hz without packet loss. The entire system weighs under 20 kg and can be assembled in less than 45 minutes.</p> Subsystem Key Components Function Sensing ICM-45686 IMU (6-axis) Captures motion and vibration up to 1 kHz Processing ESP32 dual-core MCU Computes inverse kinematics &amp; PID control Transmission BLE GATT protocol Low-latency data relay (&lt; 10 ms) Actuation 3 \u00d7 24 V DC worm-gear linear actuators Generate seat tilt (pitch/roll) Power 24 V 10 A DC supply Shared source for actuators &amp; logic Feedback 5\u201310 Hz vibration motor Simulates terrain resonance"},{"location":"remote_chair/#mechanical-design-and-kinematics","title":"Mechanical Design and Kinematics","text":"<p>The mechanical platform is triangular and symmetric, each actuator mounted at 0\u00b0, 120\u00b0, and 240\u00b0. This configuration balances torque loads, minimizes moment coupling, and reduces the number of control equations from six (in full Stewart systems) to three, maintaining 2-DOF control (pitch, roll) while preserving realism.</p>"},{"location":"remote_chair/#key-structural-highlights","title":"Key Structural Highlights","text":"<ul> <li>Actuator Thrust: 980 N (100 kgf per unit)  </li> <li>Effective Torque: ~12.8 N\u00b7m per actuator at \u00b115\u00b0 tilt  </li> <li>Frame Material: 6061-T6 aluminum profile with 9 mm plywood seat  </li> <li>Bearing Interfaces: M8 rod-end ball joints to absorb lateral shear  </li> <li>Base Geometry: Equilateral triangle, side length 540 mm  </li> <li>Center Height (rest): 230 mm \u2192 variable up to \u00b145 mm during tilt  </li> </ul> <p>Finite Element Analysis (FEA) results show maximum deformation of 0.47 mm at 800 N load, corresponding to a Von Mises stress of 42.3 MPa, well below the aluminum yield strength (\u2248 275 MPa). Safety factor: &gt; 3.1 under full tilt and payload conditions.</p> <p>The inverse kinematics model converts desired Euler angles to actuator lengths via precomputed lookup tables, updated at 200 Hz. This ensures real-time motion synchronization with minimal computational overhead on ESP32.</p>"},{"location":"remote_chair/#control-and-electronics","title":"Control and Electronics","text":""},{"location":"remote_chair/#sensor-sampling","title":"Sensor &amp; Sampling","text":"<p>The ICM-45686 IMU is configured for 1 kHz raw sampling, averaged to 100 Hz for transmission stability. Its digital motion processor (DMP) reduces noise and bias drift using a complementary Kalman filter.</p>"},{"location":"remote_chair/#communication-timing","title":"Communication &amp; Timing","text":"<p>BLE is configured with: - Connection interval: 7.5 ms - MTU size: 247 bytes - Transmission rate: 300 packets/s (orientation + vibration data) Latency tests show mean 7.3 ms delay, 99th percentile &lt; 9.4 ms, even under high interference.</p>"},{"location":"remote_chair/#actuation-feedback","title":"Actuation &amp; Feedback","text":"<ul> <li>BTS7960 Motor Drivers (43 A peak): PWM range 1\u20132 kHz, dual-direction control.  </li> <li>PID loop frequency: 200 Hz; tuned via Ziegler\u2013Nichols method for critical damping (Kp = 2.1, Ki = 0.4, Kd = 0.12).  </li> <li>PWM resolution: 12-bit native hardware control.  </li> <li>Vibration Actuator: Driven by PWM (0\u2013255) mapped to vibration intensity, frequency 5\u201310 Hz (engine resonance band).</li> </ul>"},{"location":"remote_chair/#power-management","title":"Power Management","text":"<p>All systems share a regulated 24 V 10 A DC bus with reverse-polarity protection and EMI filter. Measured steady-state power draw: ~110 W, peak startup: &lt; 160 W. Thermal analysis confirmed continuous operation below 55\u00b0C at full duty.</p>"},{"location":"remote_chair/#firmware-and-software","title":"Firmware and Software","text":"<p>ESP32\u2019s dual-core FreeRTOS design enables fully asynchronous operation:</p> Core Process Description Core 0 BLE stack Handles GATT communication and packet integrity Core 1 Control loop Executes kinematics, PID, and PWM updates"},{"location":"remote_chair/#thread-breakdown","title":"Thread Breakdown","text":"<ul> <li>Task 1: IMU read \u2192 DMP filtering \u2192 queue buffer (1 kHz \u2192 100 Hz)  </li> <li>Task 2: BLE transmit \u2192 checksum validation (every 3 ms)  </li> <li>Task 3: Inverse kinematics + PWM update (5 ms cycle)  </li> <li>Task 4: Vibration motor modulation (adaptive rate 5\u201310 Hz)  </li> </ul> <p>Lookup tables were precomputed for angle-to-stroke mapping, cutting onboard computation time by 60%. BLE retransmission queue ensures 0.00 % packet loss at up to 2.4 GHz channel interference.</p>"},{"location":"remote_chair/#experimental-validation","title":"Experimental Validation","text":"<p>All subsystems underwent systematic testing and calibration.</p> Test Type Metric Measured Result Remarks Tilt accuracy &lt; 0.9\u00b0 avg error \u00b115\u00b0 motion 5\u00b0 step motion, 10 cycles Latency 7.3 ms mean BLE + PWM pipeline &lt; 10 ms end-to-end Vibration Reproduction 5\u201380 Hz range Peak sensitivity 5\u201310 Hz Human resonance frequency Actuator Speed 83.7 mm/s Full stroke 3.7 s Verified via encoder Payload Capacity &gt; 1000 N 3.0\u00d7 safety factor Structural stability Runtime Endurance 90 min Stable temp &lt; 55\u00b0C Full demo Power Draw 110 W avg 24 V supply No overcurrent events <p>Data logging using a 1000 Hz timestamped serial stream confirmed temporal synchronization between source and replica chairs with correlation coefficient r = 0.984 (5 Hz motion cycles).</p>"},{"location":"remote_chair/#results-discussion","title":"Results Discussion","text":"<p>The RFMC system achieved human-perceptible realism with negligible delay and noise-induced jitter. Subjective trials rated feedback realism at 4.6 / 5.0 for tilt response and 4.4 / 5.0 for vibration clarity. Unlike high-cost 6-DOF Stewart platforms (typically &gt; 10 000 USD), the proposed 3-actuator variant achieved equivalent dynamic response using hardware totaling &lt; 400 USD.</p> <p>Comparative benchmarks vs. commercial systems:</p> System DOF Latency (ms) Load (N) Cost (USD) SimCraft APEX 3 3 12\u201315 1300 14 000 D-BOX G5 3 10\u201312 1000 8 000 RFMC (ours) 2 7\u20139 1000 ~400"},{"location":"remote_chair/#applications-and-future-work","title":"Applications and Future Work","text":"<p>Applications - Remote machinery operation (crane, excavator) - Training simulators for heavy-vehicle operators - Rehabilitation chairs for vestibular therapy - Remote telepresence in hazardous environments</p> <p>Future Enhancements 1. Integrate force sensors on actuators for closed-loop bidirectional feedback. 2. Expand motion to 6-DOF by adding heave, surge, yaw axes. 3. Replace BLE with Wi-Fi 6E or private 5G for long-distance telepresence (&gt; 500 m). 4. Incorporate AI-based adaptive control for motion prediction and compensation.  </p>"},{"location":"remote_chair/#acknowledgment","title":"Acknowledgment","text":"<p>Developed by Team 1 (Jeongsoo Pang et al.) Under SJTU UM\u2013JI Capstone Design (2025) and Builder X support, this project demonstrates that haptic telepresence can be achieved using compact mechanical systems and optimized firmware with industry-grade precision.</p>"},{"location":"bayesian/","title":"Bayesian Analysis","text":""},{"location":"bayesian/#acknowledgement","title":"Acknowledgement","text":"<ul> <li>Professor Ailin Zhang</li> <li>STAT4510: Bayesian Analysis</li> </ul>"},{"location":"bayesian/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Bayesian foundations and motivation</li> <li>Review of probability distributions and MLE</li> <li>Prior distributions and Bayesian logic</li> <li>Types and properties of priors</li> <li>Posterior inference mechanics</li> <li>Interval estimation and prediction</li> <li>Hypothesis testing and model comparison</li> <li>Loss functions and optimal decisions</li> <li>Computational methods for Bayes</li> </ol>"},{"location":"bayesian/computation/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/foundations/","title":"1. Bayesian foundations and motivation","text":"<p>Author: Jeongsoo Pang  </p>"},{"location":"bayesian/foundations/#1-concept","title":"1) Concept","text":"<p>Bayesian Statistical Inference:  - A framework that uses Bayes\u2019 Rule to combine prior knowledge with observed data, forming a posterior belief about unknown parameters.</p> <p>Core Idea - Treat parameters as random variables with probability distributions rather than fixed values.</p> <p>Focus - Uncertainty quantification, knowledge updating, and probabilistic reasoning.  </p>"},{"location":"bayesian/foundations/#motivation","title":"Motivation","text":"<p>Integrates prior knowledge - Encodes existing beliefs or domain expertise.  </p> <p>Logical updating - Adjusts those beliefs as new data arrive.  </p> <p>Probabilistic conclusions - Allows probability statements about parameters - ex) \u201cThere\u2019s a 95% probability \\(\\theta\\) lies in this range\u201d</p> <p>Transparent modeling - Easy to test sensitivity to assumptions.  </p>"},{"location":"bayesian/foundations/#3-core-equation-bayes-rule","title":"3) Core Equation (Bayes\u2019 Rule)","text":"\\[ p(\\theta \\mid x) \\;=\\; \\frac{p(x \\mid \\theta)\\,p(\\theta)}{p(x)} \\;\\propto\\; p(x \\mid \\theta)\\,p(\\theta) \\] <ul> <li>Posterior: Updated belief after observing data.  </li> <li>Likelihood: Information from observed data.  </li> <li>Prior: Belief before observing data.  </li> <li>Evidence (marginal likelihood): Normalizing constant ensuring posterior integrates to 1.  </li> </ul>"},{"location":"bayesian/foundations/#key-terms","title":"Key Terms","text":"<ul> <li>Prior \\(p(\\theta)\\): Belief about \\(\\theta\\) before seeing data.  </li> <li>Likelihood \\(p(x \\mid \\theta)\\): Probability of data given \\(\\theta\\).  </li> <li>Posterior \\(p(\\theta \\mid x)\\): Updated belief after seeing data.  </li> <li>Evidence \\(p(x)\\): Normalizing term for comparison across models.  </li> <li>Predictive Distribution \\(p(x_{\\text{new}} \\mid x)\\): Predicts unseen data, integrating over parameter uncertainty.  </li> </ul>"},{"location":"bayesian/foundations/#4-bayesian-vs-frequentist","title":"4) Bayesian vs. Frequentist","text":"Aspect Bayesian Frequentist Parameter Random variable with distribution Fixed but unknown value Data Observed once; updates belief Repeated hypothetical samples Output Posterior probability Point estimate + confidence interval Inference Probabilistic about parameters Probabilistic about data"},{"location":"bayesian/foundations/#5-where-bayesian-appears-in-mlcs","title":"5) Where \u201cBayesian\u201d Appears in ML/CS","text":"<p>Na\u00efve Bayes Classifier  - Spam detection - uses \\(P(\\text{spam} \\mid \\text{email}) \\propto P(\\text{email} \\mid \\text{spam})\\,P(\\text{spam})\\).  </p> <p>Bayesian Networks - Directed Acyclic Graphs (DAGs) modeling dependencies among variables - useful for causal inference and probabilistic reasoning.  </p> <p>Bayesian Optimization  - Efficient search for global minima of costly black-box functions - ex) hyperparameter tuning or A/B testing</p> <p>Bayesian Experimental Design - Adaptive experiments minimizing sample or cost - ex) early-stopping in clinical trials</p>"},{"location":"bayesian/foundations/#6-reason-for-resurgence","title":"6) Reason for Resurgence","text":"<ul> <li>Computational Power: GPUs and MCMC algorithms make complex Bayesian models practical.  </li> <li>Cultural Shift: Acceptance of subjective priors and probabilistic thinking.  </li> <li>Educational Change: Modern statistics courses incorporate Bayesian reasoning.  </li> </ul>"},{"location":"bayesian/foundations/#7-bayesian-workflow","title":"7) Bayesian Workflow","text":"<ol> <li>Specify Prior: Choose distribution for parameter \\(\\theta\\).  </li> <li>Select Likelihood: Define model generating data.  </li> <li>Compute Posterior: Combine prior and likelihood via Bayes\u2019 rule.  </li> <li>Summarize Inference: Use MAP, posterior mean, variance, or credible intervals.  </li> <li>Make Decisions: Apply posterior to decision problems (e.g., minimize expected loss).  </li> </ol>"},{"location":"bayesian/foundations/#8-mini-example-naive-bayes-for-spam","title":"8) Mini Example \u2013 Na\u00efve Bayes for Spam","text":"\\[ P(\\text{spam} \\mid \\text{email}) \\;\\propto\\; P(\\text{email} \\mid \\text{spam})\\,P(\\text{spam}) \\] <ul> <li>Assumption: Words are conditionally independent given class.  </li> <li>Result: Fast training, interpretable features, still used for baseline text classification.  </li> </ul>"},{"location":"bayesian/foundations/#12-summary-quote","title":"12) Summary Quote","text":"<p>Bayesian inference formalizes learning from data by updating prior beliefs with evidence to obtain a posterior. It enables rational, probabilistic reasoning for real-world uncertainty which is foundational to modern machine learning and decision-making.</p>"},{"location":"bayesian/hypothesis-models/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/intervals-prediction/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/loss-decisions/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/mle-review/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/posterior-inference/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/priors-logic/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"bayesian/priors-types/","title":"Page Title","text":"<p>Work-in-progress.</p>"},{"location":"images/","title":"IMAGES","text":""},{"location":"os/","title":"Operating Systems","text":""},{"location":"os/#acknowledgement","title":"Acknowledgement","text":"<ul> <li>Professor Manuel Charlemagne</li> <li>ECE4820 Introduction to Operation Systems</li> </ul>"},{"location":"os/#table-of-contents","title":"Table of Contents","text":""},{"location":"os/#1-critical-section","title":"1. Critical Section","text":""},{"location":"os/critical_section/","title":"OS : Critical Section","text":"<ul> <li>Author: Jeongsoo Pang  </li> </ul>"},{"location":"os/critical_section/#1-concept","title":"1) Concept","text":"<ul> <li>Critical Section (CS): A section of code that accesses shared state, however, must not be executed by more than one thread/process at the same time.</li> <li>Goal: Prevent race conditions (nondeterministic bugs caused by interleavings of reads/writes to shared data).. Classic symptoms of a race:</li> <li>Lost updates (A writes, then B overwrites).</li> <li>Read of inconsistent/partial state.</li> <li>Occasional test flakiness that \u201cgoes away\u201d when adding prints or sleeps.</li> </ul>"},{"location":"os/critical_section/#2-the-critical-section-problem","title":"2) The \u201cCritical Section Problem\u201d","text":"<p>A correct solution enforces 3-properties (by Dijkstra):</p> <p>1. Mutual Exclusion  - At most one thread is inside the CS at any time.</p> <p>2. Progress  - If no thread is inside the CS, one of the threads wishing to enter must be able to proceed.</p> <p>3. Bounded Waiting (No Starvation)  - There is a finite bound on the number of times other threads can enter their CS after a thread has requested entry and before it gets in.</p>"},{"location":"os/critical_section/#3-the-4-part-structure-of-concurrent-code","title":"3) The 4-part Structure of Concurrent Code","text":"<pre><code>1. Entry Section -&gt; 2. Critical Section -&gt; 3. Exit Section -&gt; 4. Remainder Section\n (check/acquire)      (touch shared)          (release)          (private work)\n</code></pre> <ul> <li>Entry: Acquire the right to enter the CS (lock, protocol).</li> <li>Critical Section: Access/modify shared state.</li> <li>Exit: Release the right (unlock, clear flags).</li> <li>Remainder: Do private or non-shared work.</li> </ul>"},{"location":"os/critical_section/#5-classic-software-only-algorithms","title":"5) Classic Software-Only Algorithms","text":"<p>Work on sequential consistency and shared memory. Useful to understand progress/bounded waiting.</p>"},{"location":"os/critical_section/#51-petersons-algorithm-2-threads","title":"5.1 Peterson\u2019s Algorithm (2 threads)","text":"<pre><code>// Shared\nvolatile bool want[2] = {false, false};\nvolatile int turn = 0;\n\n// Thread i (i in {0,1}):\nwant[i] = true;\nturn = 1 - i;\nwhile (want[1 - i] &amp;&amp; turn == 1 - i) {\n/* busy wait /\n}\n\n/ ---- Critical Section ---- */\nwant[i] = false;\n</code></pre> <ul> <li>Satisfies mutual exclusion, progress, bounded waiting (under SC).</li> <li>Mostly pedagogical; compilers/CPUs reorder \u2192 needs memory barriers in practice.</li> </ul>"},{"location":"os/critical_section/#6-hardware-support-atomic-primitives","title":"6) Hardware Support: Atomic Primitives","text":"<p>Modern solutions rely on atomic read-modify-write (RMW) instructions: - Test-and-Set (TAS):</p> <pre><code>bool test_and_set(bool *x) {\nbool old = *x;\n*x = true;\nreturn old;\n}\n</code></pre> <ul> <li>Compare-and-Swap (CAS): <code>CAS(addr, expected, new)</code> atomically does:</li> </ul> <pre><code>if (*addr == expected) { *addr = new; return true; } else return false;\n</code></pre> <ul> <li>Fetch-and-Add (FAA), XCHG, or LL/SC (Load-Linked/Store-Conditional).</li> </ul> <p>Memory Ordering: Many CPUs are not sequentially consistent. Use: - Acquire on loads that observe a lock; Release on stores that unlock. - Fences/barriers as needed (e.g., <code>atomic_thread_fence(memory_order_seq_cst)</code>). - In C/C++ atomics, pair <code>memory_order_acquire</code> with <code>memory_order_release</code>.</p>"},{"location":"os/critical_section/#7-locks-and-locking-primitives","title":"7) Locks and Locking Primitives","text":""},{"location":"os/critical_section/#71-spinlock-busy-wait","title":"7.1 Spinlock (busy-wait)","text":"<p>Use when CS is very short and threads are truly running on different CPUs.</p> <pre><code>// TAS spinlock\nstd::atomic&lt;bool&gt; locked{false};\n\nvoid lock() {\nwhile (locked.exchange(true, std::memory_order_acquire)) {\n// spin\n}\n}\n\nvoid unlock() {\nlocked.store(false, std::memory_order_release);\n}\n</code></pre> <ul> <li>Pros: Simple, low latency for tiny CS.</li> <li>Cons: Wastes CPU cycles; terrible if CS may block/sleep or be long. Improvements:</li> </ul>"},{"location":"os/critical_section/#72-mutex-sleeping-lock","title":"7.2 Mutex (sleeping lock)","text":"<p>Use when CS can be longer or a thread may block inside CS.</p> <ul> <li>If lock unavailable, the kernel places thread on a wait queue.</li> <li>Often features: fairness, priority inheritance, timed trylock.</li> </ul> <pre><code>pthread_mutex_lock(&amp;m);\n\n/* critical section */\npthread_mutex_unlock(&amp;m);\n</code></pre>"},{"location":"os/critical_section/#73-readerwriter-sharedexclusive-locks","title":"7.3 Reader\u2013Writer (Shared/Exclusive) Locks","text":"<ul> <li>Multiple readers can enter concurrently (writers need exclusivity).</li> <li>Variants: Reader-preferred, Writer-preferred, Fair.</li> <li>Be careful: Reader preference can starve writers.</li> </ul>"},{"location":"os/critical_section/#8-higher-level-constructs","title":"8) Higher-Level Constructs","text":""},{"location":"os/critical_section/#81-semaphores","title":"8.1 Semaphores","text":"<ul> <li>Counting semaphore: integer \u2265 0 with <code>P()/wait()</code> and <code>V()/signal()</code>.</li> <li>Binary semaphore \u2248 mutex (but with different semantics = no ownership).</li> <li>Great for resource counting and producer\u2013consumer.</li> </ul> <pre><code>semaphore empty = N; // free slots\nsemaphore full = 0; // filled slots\nmutex m = 1;\n\nproducer:\nwait(empty);\nwait(m);\nput(item);\nsignal(m);\nsignal(full);\n\nconsumer:\nwait(full);\nwait(m);\nget(item);\nsignal(m);\nsignal(empty);\n</code></pre>"},{"location":"os/critical_section/#82-monitors","title":"8.2 Monitors","text":"<ul> <li>Language-level construct: only one thread executes a monitor\u2019s method at a time (implicit mutual exclusion).</li> <li>Condition variables (CVs) inside a monitor provide waiting and signaling:   -\\ <code>wait(cv)</code>: atomically releases the monitor lock and blocks.   -\\ <code>signal(cv)</code> or <code>broadcast(cv)</code>: wake one/all waiting threads.</li> </ul>"},{"location":"os/critical_section/#9-kernel-vs-user-space","title":"9) Kernel vs. User Space","text":"Aspect User Space Kernel Space Notes Typical primitives <code>pthread_mutex</code>, <code>pthread_rwlock</code>, <code>pthread_cond</code>, semaphores (POSIX) spinlocks, mutexes (<code>mutex</code>/<code>rwsem</code>), RCU, seqlocks, futex backends User locks often use futex to sleep in kernel on contention. Contention behavior Starts in user mode; enters kernel only when contended (futex wait/wake) Fully managed by kernel; may spin or sleep based on lock type and context Minimizes syscalls on fast path in user space. Preemption/interrupts Cannot disable either Can disable preemption/IRQs for very short CS on a CPU Disabling IRQs \u2260 cross-CPU exclusion. Critical-section duration Usually longer; may block (I/O, syscalls) Very short for spin; sleeping locks for longer/IO-touching regions Spin only for microseconds. Sleep inside CS? Allowed with mutex/RW locks (not with user spinlocks) Never while holding spinlocks; allowed with sleeping locks Holding a spinlock + sleep \u2192 bug. Fairness/starvation controls Fair mutexes; RW lock policies (reader/writer pref, fair) Ticket/MCS locks, prio-aware policies Kernel often provides stronger fairness knobs. Priority inversion handling Via priority inheritance (PI) mutexes (e.g., <code>pthread_mutexattr_setprotocol</code>) PI/PCP mechanisms on kernel mutexes Use PI for real-time threads. Memory ordering C/C++ atomics with acquire/release + fences Architecture-specific barriers; lock/unlock imply ordering Same principles; different primitives. Wakeups Futex wake by kernel (targeted wake) Wait-queues, <code>wake_up*</code> APIs Both try to avoid thundering herd. Examples App queues, caches, work pools Scheduler runqueues, inode caches, networking fast paths Choose primitives by context."},{"location":"os/critical_section/#10-worked-examples","title":"10) Worked Examples","text":""},{"location":"os/critical_section/#101-protecting-a-shared-counter","title":"10.1 Protecting a Shared Counter","text":"<p>Incorrect:</p> <pre><code>// race: i++ is read-modify-write\ni++;\n</code></pre> <p>Correct (mutex):</p> <pre><code>pthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\n\nvoid increment() {\n  pthread_mutex_lock(&amp;m);\n  i++;\n  pthread_mutex_unlock(&amp;m);\n}\n</code></pre> <p>Correct (atomic, lock-free):</p> <pre><code>std::atomic&lt;int&gt; i{0};\nvoid increment() {\n  i.fetch_add(1, std::memory_order_relaxed);\n}\n</code></pre> <p>If other invariants exist around <code>i</code>, you might need stronger ordering.</p>"},{"location":"os/critical_section/#102-producerconsumer-with-condition-variables-mesa-semantics","title":"10.2 Producer\u2013Consumer with Condition Variables (Mesa semantics)","text":"<pre><code>std::queue&lt;int&gt; q;\nconst size_t CAP = 1024;\npthread_mutex_t m = PTHREAD_MUTEX_INITIALIZER;\npthread_cond_t not_full = PTHREAD_COND_INITIALIZER;\npthread_cond_t not_empty = PTHREAD_COND_INITIALIZER;\n\nvoid produce(int item) {\n  pthread_mutex_lock(&amp;m);\n  while (q.size() == CAP)\n  pthread_cond_wait(&amp;not_full, &amp;m);\n  q.push(item);\n  pthread_cond_signal(&amp;not_empty);\n  pthread_mutex_unlock(&amp;m);\n}\n\nint consume() {\n  pthread_mutex_lock(&amp;m);\n  while (q.empty())\n  pthread_cond_wait(&amp;not_empty, &amp;m);\n  int item = q.front(); q.pop();\n  pthread_cond_signal(&amp;not_full);\n  pthread_mutex_unlock(&amp;m);\n  return item;\n}\n</code></pre>"},{"location":"os/critical_section/#11-notes","title":"11) NOTES","text":"<ul> <li>Keep CS minimal : do not call unbounded or blocking operations inside.</li> <li>Clearly document lock ownership and lock ordering in comments.</li> <li>Use RAII/scoped guards to avoid forgotten unlocks.</li> <li>Prefer condition variables over ad-hoc sleeps : always <code>while (!cond) wait</code>.</li> <li>Consider priority inversion in real-time systems: enable priority inheritance.</li> <li>On weakly ordered CPUs, ensure correct acquire/release semantics.</li> </ul>"},{"location":"os/critical_section/#12-cheat-sheet-table-alternative","title":"12) Cheat-Sheet (table alternative)","text":"Situation Pick Short CS on multicore? Spin (TAS + backoff or MCS) May block / long CS? Mutex or RW lock Multiple readers, rare writers? Reader\u2013Writer lock or RCU Pool of N resources? Counting semaphore Waking sleepers on condition? CV with <code>while (!cond) wait</code> Avoid deadlock Global lock order + trylock fallback"},{"location":"portfolio/","title":"Portfolio","text":"<p>Portfolio</p> <ul> <li> <p>Cercare-Medical ML Project</p> </li> <li> <p>Anti-Drone Project</p> </li> <li> <p>Remote Feeling Mimicking Chair</p> </li> </ul> <p>OS</p> <ul> <li>Critical Section</li> </ul> <p>Bayesian</p> <ul> <li> <p>Foundations and motivation</p> </li> <li> <p>Review of probability distributions and MLE</p> </li> <li> <p>Prior distributions and Bayesian logic</p> </li> <li> <p>Types and properties of priors</p> </li> <li> <p>Posterior inference mechanics</p> </li> <li> <p>Interval estimation and prediction</p> </li> <li> <p>Hypothesis testing and model comparison</p> </li> <li> <p>Loss functions and optimal decisions</p> </li> <li> <p>Computational methods for Bayesian</p> </li> </ul>"}]}